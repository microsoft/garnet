"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[3193],{52673(e,t,n){n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"getting-started/compaction","title":"Log Compaction","description":"When Garnet is configured to run with storage using EnableStorageTier or --storage-tier, data that does not fit in memory will spill to disk storage.","source":"@site/docs/getting-started/compaction.md","sourceDirName":"getting-started","slug":"/getting-started/compaction","permalink":"/garnet/docs/getting-started/compaction","draft":false,"unlisted":false,"editUrl":"https://github.com/microsoft/garnet/tree/main/website/docs/getting-started/compaction.md","tags":[],"version":"current","frontMatter":{"id":"compaction","sidebar_label":"Compaction","title":"Log Compaction"},"sidebar":"garnetDocSidebar","previous":{"title":"Security","permalink":"/garnet/docs/security"},"next":{"title":"Overview","permalink":"/garnet/docs/benchmarking/overview"}}');var i=n(74848),c=n(28453);const s={id:"compaction",sidebar_label:"Compaction",title:"Log Compaction"},r=void 0,a={},d=[{value:"Triggering Compaction",id:"triggering-compaction",level:2},{value:"Compaction Strategy",id:"compaction-strategy",level:2},{value:"Segment Deletion",id:"segment-deletion",level:2}];function l(e){const t={code:"code",h2:"h2",li:"li",p:"p",ul:"ul",...(0,c.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:["When Garnet is configured to run with storage using ",(0,i.jsx)(t.code,{children:"EnableStorageTier"})," or ",(0,i.jsx)(t.code,{children:"--storage-tier"}),", data that does not fit in memory will spill to disk storage.\nData on disk is split into segments, with one physical file per segment. The size of each segment is configured using ",(0,i.jsx)(t.code,{children:"SegmentSize"})," or ",(0,i.jsx)(t.code,{children:"--segment"})," for\nthe main store, and ",(0,i.jsx)(t.code,{children:"ObjectStoreSegmentSize"})," or ",(0,i.jsx)(t.code,{children:"--obj-segment"})," for the object store."]}),"\n",(0,i.jsx)(t.p,{children:"File segments continue to get created and added over time, so we need a way to delete older segments. This is where compaction comes in."}),"\n",(0,i.jsx)(t.h2,{id:"triggering-compaction",children:"Triggering Compaction"}),"\n",(0,i.jsxs)(t.p,{children:["You can configure ",(0,i.jsx)(t.code,{children:"CompactionFrequencySecs"})," or ",(0,i.jsx)(t.code,{children:"--compaction-freq"}),", which creates a task that wakes up every so often to try compaction. If the number\nof segments on disk exceeds ",(0,i.jsx)(t.code,{children:"CompactionMaxSegments"})," or ",(0,i.jsx)(t.code,{children:"--compaction-max-segments"}),", compaction runs using the specified strategy so that we end up with\nat most ",(0,i.jsx)(t.code,{children:"CompactionMaxSegments"})," active segments. The oldest segments are our chosen candidates for compaction. For the object store, the corresponding\nswitch is ",(0,i.jsx)(t.code,{children:"ObjectStoreCompactionMaxSegments"})," or ",(0,i.jsx)(t.code,{children:"--obj-compaction-max-segments"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"compaction-strategy",children:"Compaction Strategy"}),"\n",(0,i.jsxs)(t.p,{children:["The candidate segments for compaction are processed using some strategy, specified using the\n",(0,i.jsx)(t.code,{children:"CompactionType"})," or ",(0,i.jsx)(t.code,{children:"--compaction-type"})," switch. Available options are:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"None: No compaction is performed."}),"\n",(0,i.jsx)(t.li,{children:"Shift: The inactive segments are simply marked as ready for deletion."}),"\n",(0,i.jsx)(t.li,{children:'Scan: The entire log is scanned to check which records in the candidate segments to be compacted are "live", and these live records are copied to the tail of the log (in memory).'}),"\n",(0,i.jsx)(t.li,{children:"Lookup: For every record in the candidate segments to be compacted, we perform a random lookup to check if it is live. As before, the live records are copied to the tail of the log (in memory)."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"segment-deletion",children:"Segment Deletion"}),"\n",(0,i.jsx)(t.p,{children:"After the compaction strategy is applied on the candidate segments, they are inactive and eligible for deletion. However, the inactive segments are not\nimmediately deleted from disk by default, since doing so can cause data loss in case the server crashes before taking the next checkpoint (and the AOF is disabled).\nInstead, the next checkpoint will automatically cause the deletion of the inactive segments."}),"\n",(0,i.jsxs)(t.p,{children:["In case you are not taking checkpoints and want to force the physical deletion of inactive segments immediately after the compaction strategy is applied, you can specify\nthe override ",(0,i.jsx)(t.code,{children:"CompactionForceDelete"})," or ",(0,i.jsx)(t.code,{children:"--compaction-force-delete"})," switch. Note that this option can cause data loss when we recover to the previous\ncheckpoint, in case the AOF is disabled."]})]})}function m(e={}){const{wrapper:t}={...(0,c.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453(e,t,n){n.d(t,{R:()=>s,x:()=>r});var o=n(96540);const i={},c=o.createContext(i);function s(e){const t=o.useContext(c);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(c.Provider,{value:t},e.children)}}}]);