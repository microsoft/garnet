"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[4883],{28453(e,n,s){s.d(n,{R:()=>r,x:()=>a});var t=s(96540);const i={},o=t.createContext(i);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),t.createElement(o.Provider,{value:n},e.children)}},65973(e,n,s){s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"dev/tsavorite/locking","title":"Locking","description":"There are three modes of locking in Tsavorite, set by a ConcurrencyControlMode value on the Tsavorite constructor:","source":"@site/docs/dev/tsavorite/locking.md","sourceDirName":"dev/tsavorite","slug":"/dev/tsavorite/locking","permalink":"/garnet/docs/dev/tsavorite/locking","draft":false,"unlisted":false,"editUrl":"https://github.com/microsoft/garnet/tree/main/website/docs/dev/tsavorite/locking.md","tags":[],"version":"current","frontMatter":{"id":"locking","sidebar_label":"Locking","title":"Locking"},"sidebar":"garnetDocSidebar","previous":{"title":"Revivification","permalink":"/garnet/docs/dev/tsavorite/reviv"},"next":{"title":"StoreFunctions","permalink":"/garnet/docs/dev/tsavorite/storefunctions"}}');var i=s(74848),o=s(28453);const r={id:"locking",sidebar_label:"Locking",title:"Locking"},a="Locking",c={},d=[{value:"Considerations",id:"considerations",level:2},{value:"Example",id:"example",level:2},{value:"Internal Design",id:"internal-design",level:2},{value:"Operation Data Structures",id:"operation-data-structures",level:3},{value:"HashEntryInfo",id:"hashentryinfo",level:4},{value:"RecordSource",id:"recordsource",level:4},{value:"OperationStackContext",id:"operationstackcontext",level:4},{value:"Lock Locations",id:"lock-locations",level:3},{value:"LockTable",id:"locktable",level:4},{value:"RecordInfo",id:"recordinfo",level:4},{value:"Locking Flow",id:"locking-flow",level:3},{value:"ReadCache",id:"readcache",level:3}];function l(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"locking",children:"Locking"})}),"\n",(0,i.jsxs)(n.p,{children:["There are three modes of locking in Tsavorite, set by a ",(0,i.jsx)(n.code,{children:"ConcurrencyControlMode"})," value on the Tsavorite constructor:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"LockTable"}),": Tsavorite's hash index buckets are used to hold the lock state. Locktable locking is either manual or transient:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Manual"}),": Garnet calls a ",(0,i.jsx)(n.code,{children:"Lock"})," method on ",(0,i.jsx)(n.code,{children:"LockableContext"})," or ",(0,i.jsx)(n.code,{children:"LockableUnsafeContext"})," (hereafter referred to collectively as ",(0,i.jsx)(n.code,{children:"Lockable*Context"}),") at the beginning of a transaction, passing an ordered array of keys, and must call ",(0,i.jsx)(n.code,{children:"Unlock"})," when the transaction is complete. Tsavorite does not try to lock during individual operations on these session contexts."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transient"}),": Tsavorite acquires and releases locks for individual keys for the duration of a data operation: Upsert, RMW, Read, or Delete. Collectively, these are referred to here as ",(0,i.jsx)(n.code,{children:"InternalXxx"})," for the internal methods that implement them."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"None"}),": No locking is done by Tsavorite."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["All locks are obtained via spinning on ",(0,i.jsx)(n.code,{children:"Interlocked.CompareExchange"})," and ",(0,i.jsx)(n.code,{children:"Thread.Yield()"})," and have limited spin count, to avoid deadlocks; if they fail to acquire the desired lock in this time, the operation retries."]}),"\n",(0,i.jsxs)(n.p,{children:["As noted above, manual locking is done by obtaining the ",(0,i.jsx)(n.code,{children:"Lockable*Context"})," instance from a ",(0,i.jsx)(n.code,{children:"ClientSession"}),". There are currently 4 ",(0,i.jsx)(n.code,{children:"*Context"})," implementations; all are ",(0,i.jsx)(n.code,{children:"struct"})," for inlining. All ",(0,i.jsx)(n.code,{children:"*Context"})," are obtained as properties on the ",(0,i.jsx)(n.code,{children:"ClientSession"})," named for the type (e.g. ",(0,i.jsx)(n.code,{children:"clientSession.LockableContext"}),"). The characteristics of each ",(0,i.jsx)(n.code,{children:"*Context"})," are:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"BasicContext"})}),": This is exactly the same as ",(0,i.jsx)(n.code,{children:"ClientSession"}),", internally calling directly through to ",(0,i.jsx)(n.code,{children:"ClientSession"}),"'s methods and reusing ",(0,i.jsx)(n.code,{children:"ClientSession"}),"'s ",(0,i.jsx)(n.code,{children:"TsavoriteSession"}),". It provides safe epoch management (acquiring and releasing the epoch on each call) and Transient locking."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"UnsafeContext : IUnsafeContext"})}),': This provides Transient locking, but rather than safe epoch management handled per-operation by Tsavorite, this supports "unsafe" manual epoch management controlled by the client via ',(0,i.jsx)(n.code,{children:"BeginUnsafe()"})," and ",(0,i.jsx)(n.code,{children:"EndUnsafe()"}),"; it is the client's responsibility to make these calls correctly. ",(0,i.jsx)(n.code,{children:"UnsafeContext"}),' API methods call the internal ContextRead etc. methods without doing the Resume and Suspend (within try/finally) of epoch protection as is done by the "Safe" API methods.']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"LockableContext : ILockableContext"})}),": This provides safe epoch management, but rather than Transient locking, this requires Manual locks via ",(0,i.jsx)(n.code,{children:"BeginLockable"})," and ",(0,i.jsx)(n.code,{children:"EndLockable"}),". This requirement ensures that all locks are acquired before any methods accessing those keys are called."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"LockableUnsafeContext : ILockableContext, IUnsafeContext"})}),": This combines manual epoch management and manual locking, exposing both sets of methods."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["In addition to the ",(0,i.jsx)(n.code,{children:"Lock"})," methods, Tsavorite supports:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"TryLock"}),": Accepts an array of keys and returns true if all locks were acquired, else false (and any locks that were acquired are released)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"TryPromoteLock"}),": Accepts a single key and returns true if the key's lock could be promoted from Read to Exclusive."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"considerations",children:"Considerations"}),"\n",(0,i.jsx)(n.p,{children:"All manual locking of keys must lock the keys in a deterministic order, and unlock in the reverse order, to avoid deadlocks."}),"\n",(0,i.jsx)(n.p,{children:"Lock spinning is limited in order to avoid deadlocks such as the following:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"Lockable*Context"})," LC1 exclusively locks k1"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"BasicContext"})," BC1 tries to acquire an exclusive Transient lock on k1, and spins while holding the epoch"]}),"\n",(0,i.jsxs)(n.li,{children:["LC1 does an RMW on k1 resulting in a CopyUpdate; this does a BlockAllocate that finds it must flush pages from the head of the log in order to make room at the tail.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"LC1 therefore calls BumpCurrentEpoch(... OnPagesClosed)"}),"\n",(0,i.jsx)(n.li,{children:"Because BC1 holds the epoch, the OnPagesClosed() call is never drained, so we have deadlock\nBy ensuring that locks are limited in spins, we force one or both of the above sessions to release any locks it has already aquired and return up the callstack to retry the operation via RETRY_LATER (which refreshes the epoch, allowing other operations such as the OnPagesClosed() mentioned above to complete)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Transient locks are never held across pending I/O or other Wait operations. All the data operations' low-level implementors (",(0,i.jsx)(n.code,{children:"InternalRead"}),", ",(0,i.jsx)(n.code,{children:"InternalUpsert"}),", ",(0,i.jsx)(n.code,{children:"InternalRMW"}),", and ",(0,i.jsx)(n.code,{children:"InternalDelete"}),"--collectively known as ",(0,i.jsx)(n.code,{children:"InternalXxx"}),") release these locks when the call is exited; if the operations must be retried, the locks are reacquired as part of the normal operation there."]}),"\n",(0,i.jsx)(n.h2,{id:"example",children:"Example"}),"\n",(0,i.jsxs)(n.p,{children:["Here is an example of the above two use cases, condensed from the unit tests in ",(0,i.jsx)(n.code,{children:"LockableUnsafeContextTests.cs"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cs",children:"    var luContext = session.GetLockableUnsafeContext();\n    luContext.BeginUnsafe();\n    luContext.BeginLockable();\n\n    var keys = new[]\n    {\n        new FixedLengthLockableKeyStruct<long>(readKey24, LockType.Shared, luContext),      // Source, shared\n        new FixedLengthLockableKeyStruct<long>(readKey51, LockType.Shared, luContext),      // Source, shared\n        new FixedLengthLockableKeyStruct<long>(resultKey, LockType.Exclusive, luContext),   // Destination, exclusive\n    };\n\n    // Sort the keys to guard against deadlock\n    luContext.SortKeyHashes(keys);\n\n    Assert.IsTrue(luContext.TryLock(keys));\n\n    luContext.Read(key24, out var value24);\n    luContext.Read(key51, out var value51);\n    luContext.Upsert(resultKey, value24 + value51);\n\n    luContext.Unlock(keys);\n\n    luContext.EndLockable();\n    luContext.EndUnsafe();\n"})}),"\n",(0,i.jsx)(n.h2,{id:"internal-design",children:"Internal Design"}),"\n",(0,i.jsx)(n.p,{children:"This section covers the internal design and implementation of Tsavorite's locking."}),"\n",(0,i.jsx)(n.h3,{id:"operation-data-structures",children:"Operation Data Structures"}),"\n",(0,i.jsxs)(n.p,{children:["There are a number of variables necessary to track the main hash table entry information, the 'source' record as defined above, and other stack-based data relevant to the operation. These variables are placed within structs that live on the stack at the ",(0,i.jsx)(n.code,{children:"InternalXxx"})," level."]}),"\n",(0,i.jsx)(n.h4,{id:"hashentryinfo",children:"HashEntryInfo"}),"\n",(0,i.jsx)(n.p,{children:"This is used for hash-chain traversal and CAS updates. It consists primarily of:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The key's hash code and associated tag."}),"\n",(0,i.jsxs)(n.li,{children:["a stable copy of the ",(0,i.jsx)(n.code,{children:"HashBucketEntry"})," at the time the ",(0,i.jsx)(n.code,{children:"HashEntryInfo"})," was populated.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["This has both ",(0,i.jsx)(n.code,{children:"Address"})," (which may or may not include the readcache bit) and ",(0,i.jsx)(n.code,{children:"AbsoluteAddress"})," (",(0,i.jsx)(n.code,{children:"Address"})," stripped of the readcache bit) accessors."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:['a pointer (in the unsafe "C/C++ *" sense) to the live ',(0,i.jsx)(n.code,{children:"HashBucketEntry"})," that may be updated by other sessions as our current operation proceeds.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["As with the stable copy, this has two address accessors: ",(0,i.jsx)(n.code,{children:"CurrentAddress"})," (which may or may not include the readcache bit) and ",(0,i.jsx)(n.code,{children:"AbsoluteCurrentAddress"})," (",(0,i.jsx)(n.code,{children:"CurrentAddress"})," stripped of the readcache bit)."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["A method to update the stable copy of the ",(0,i.jsx)(n.code,{children:"HashBucketEntry"})," with the current information from the 'live' pointer."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"recordsource",children:"RecordSource"}),"\n",(0,i.jsxs)(n.p,{children:["This is implemented as ",(0,i.jsx)(n.code,{children:"RecordSource<TKey, TValue>"})," and carries the information identifying the source record and lock information for that record:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Whether there is an in-memory source record, and if so:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"its logical and physical addresses"}),"\n",(0,i.jsx)(n.li,{children:"whether it is in the readcache or main log"}),"\n",(0,i.jsx)(n.li,{children:"whether it is locked"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["The latest logical address of this key hash in the main log. If there are no readcache records, then this is the same as the ",(0,i.jsx)(n.code,{children:"HashEntryInfo"})," Address;"]}),"\n",(0,i.jsxs)(n.li,{children:["If there are readcache records in the chain, then ",(0,i.jsx)(n.code,{children:"RecordSource"})," contains the lowest readcache logical and physical addresses. These are used for 'splicing' a new main-log record into the gap between the readcache records and the main log recoreds; see ",(0,i.jsx)(n.a,{href:"#readcache",children:"ReadCache"})," below."]}),"\n",(0,i.jsx)(n.li,{children:"The log (readcache or hlog) in which the source record, if any, resides. This is hlog unless there is a source readcache record."}),"\n",(0,i.jsx)(n.li,{children:"Whether a LockTable lock was acquired. This is exclusive with in-memory locks; only one should be set."}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"operationstackcontext",children:"OperationStackContext"}),"\n",(0,i.jsx)(n.p,{children:"This contains all information on the stack that is necessary for the operation, making parameter lists much smaller. It contains:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.code,{children:"HashEntryInfo"}),"  and ",(0,i.jsx)(n.code,{children:"RecordSource<TKey, TValue>"})," for this operation. These are generally used together, and in some situations, such as when hlog.HeadAddress has changed due to an epoch refresh, ",(0,i.jsx)(n.code,{children:"RecordSource<TKey, TValue>"})," is reinitialized from ",(0,i.jsx)(n.code,{children:"HashEntryInfo"})," during the operation."]}),"\n",(0,i.jsxs)(n.li,{children:["the logical address of a new record created for the operation. This is passed back up the chain so the try/finally can set it invalid and non-tentative on exceptions, without having to pay the cost of a nested try/finally in the ",(0,i.jsx)(n.code,{children:"CreateNewRecord*"})," method."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"lock-locations",children:"Lock Locations"}),"\n",(0,i.jsx)(n.p,{children:"This section discusses where locks are actually stored."}),"\n",(0,i.jsx)(n.h4,{id:"locktable",children:"LockTable"}),"\n",(0,i.jsxs)(n.p,{children:["For HashTable locking, the key is hashed to its code which is modulo'd to find the hash table bucket index. This bucket consists of a vector of 8 ",(0,i.jsx)(n.code,{children:"HashBucketEntries"})," (cache-aligned, as each HashBucketEntry contains only a 'long'). The entries are organized by 'tags', which are the upper 14 bits of the hashcode. The 8th ",(0,i.jsx)(n.code,{children:"HashBucketEntry"})," is used as a linked list to an overflow bucket; its Address property is a separate allocation that points to an overflow bucket. Thus, a bucket contains 7 entries and a pointer to another bucket if more than 7 tags have been found."]}),"\n",(0,i.jsxs)(n.p,{children:["Following is a simplified overfire of the 'tag' logic, using ",(0,i.jsx)(n.code,{children:"FindOrCreateTag"})," as an example:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Iterate the first 7 entries of all buckets, including overflow. If the tag is found, use that entry."}),"\n",(0,i.jsx)(n.li,{children:"Otherwise, if an empty entry was found, assign this tag to the first empty entry and use that entry."}),"\n",(0,i.jsxs)(n.li,{children:["otherwise, add an overflow bucket and repeat the first two steps in that bucket.\n(",(0,i.jsx)(n.code,{children:"FindTag"})," is simpler, since it does not have to add an entry; it returns false if the tag is not found)."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["For the first bucket, the tag bits of its overflow entry are used for locking; see the ",(0,i.jsx)(n.code,{children:"HashBucket"})," class for detailed comments. There are 16 tag bits; for locking, 15 bits are used for shared (Read) locking and one bit for exclusive locking."]}),"\n",(0,i.jsxs)(n.p,{children:["Thus, a key is locked indirectly, by having its ",(0,i.jsx)(n.code,{children:"HashBucket"})," locked. This may result in multiple keys being locked (all keys that hash to that bucket) rather than just the required key."]}),"\n",(0,i.jsx)(n.h4,{id:"recordinfo",children:"RecordInfo"}),"\n",(0,i.jsxs)(n.p,{children:["Some relevant ",(0,i.jsx)(n.code,{children:"RecordInfo"})," bits:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Sealed"}),": A record marked Sealed has been superseded by an update (and the record may be in the Revivification FreeList). Sealing is necessary because otherwise one thread could do an RCU (Read, Copy, Update) with a value too large to be an IPU (In-Place Update), while at the same time another thread could do an IPU with a value small enough to fit. A thread encountering a Sealed record should immediately return RETRY_LATER (it must be RETRY_LATER instead of RETRY_NOW, because the thread owning the Seal must do another operation, such as an Insert to tail, to bring things into a consistent state; this operation may require epoch refresh)."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Sealing is done via ",(0,i.jsx)(n.code,{children:"RecordInfo.Seal"}),". This is only done when the ",(0,i.jsx)(n.code,{children:"LockTable"})," entry is already exclusively locked, so ",(0,i.jsx)(n.code,{children:"Seal()"})," does a simple bitwise operation."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Invalid"}),": This indicates that the record is to be skipped, using its ",(0,i.jsx)(n.code,{children:".PreviousAddress"}),' to move along the chain, rather than restarted. This "skipping" semantic is primarily relevant to the readcache; we should not have invalid records in the main log\'s hash chain. Indeed, any main-log record that is not in the hash chain ',(0,i.jsx)(n.em,{children:"must"})," be marked Invalid."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["In the ",(0,i.jsx)(n.code,{children:"ReadCache"})," we do not Seal records; the semantics of Seal are that the operation is restarted when a Sealed record is found. For non-",(0,i.jsx)(n.code,{children:"readcache"})," records, this causes the execution to restart at the tail of the main-log records. However, ",(0,i.jsx)(n.code,{children:"readcache"})," records are at the beginning of the hash chain, ",(0,i.jsx)(n.em,{children:"before"})," the main-log records; thus, restarting would start again at the hash bucket, traverse the readcache records, and hit the Sealed record again, ad infinitum."]}),"\n",(0,i.jsxs)(n.li,{children:["Thus, we instead set ",(0,i.jsx)(n.code,{children:"readcache"})," records to Invalid when they are no longer current; this allows the traversal to continue until the readcache chain links to the first main-log record."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Additionally, records may be elided (removed) from the tag chain for one of the following reasons:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The record was deleted"}),"\n",(0,i.jsx)(n.li,{children:'The record was a "source" for RCU'}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["In these cases, if the record's ",(0,i.jsx)(n.code,{children:"PreviousAddress"})," points below ",(0,i.jsx)(n.code,{children:"hlog.BeginAddress"}),", we remove the record so we do not have to waste an IO to determine that it is a superseded record."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Such elided records are put into the FreeList if it is enabled for Revivification."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"locking-flow",children:"Locking Flow"}),"\n",(0,i.jsxs)(n.p,{children:["When ",(0,i.jsx)(n.code,{children:"Internalxxx"})," when ",(0,i.jsx)(n.code,{children:"ConcurrencyControlMode"})," is ",(0,i.jsx)(n.code,{children:"LockTable"}),":"]}),"\n",(0,i.jsxs)(n.p,{children:["We obtain the key hash at the start of the operation, so we lock its bucket if we are not in a ",(0,i.jsx)(n.code,{children:"Lockable*Context"})," (if we are, we later Assert that the key is already locked)."]}),"\n",(0,i.jsx)(n.p,{children:"Following this, the requested operation is performed within a try/finally block whose 'finally' releases the lock."}),"\n",(0,i.jsx)(n.p,{children:"For RCU-like operations such as RMW or Upsert of an in-memory (including in-ReadCache) record, the source record is sealed (and may invalidate it to allow it to be freelisted for Revivification)."}),"\n",(0,i.jsxs)(n.p,{children:["Similar locking logic applies to the pending IO completion routines: ",(0,i.jsx)(n.code,{children:"ContinuePendingRead"}),", ",(0,i.jsx)(n.code,{children:"ContinuePendingRMW"}),", and ",(0,i.jsx)(n.code,{children:"ContinuePendingConditionalCopyToTail"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"readcache",children:"ReadCache"}),"\n",(0,i.jsx)(n.p,{children:"The readcache is a cache for records that are read from disk. In the case of record that become 'hot' (read multiple times) this saves multiple IOs. It is of fixed size determined at TsavoriteKV startup, and has no on-disk component; records in the ReadCache are evicted from the head without writing to disk when enough new records are added to the tail to exceed the memory-size specification."}),"\n",(0,i.jsxs)(n.p,{children:["When the ",(0,i.jsx)(n.code,{children:"ReadCache"})," is enabled, records from the ",(0,i.jsx)(n.code,{children:"ReadCache"})," are inserted into the tag chain starting at the ",(0,i.jsx)(n.code,{children:"HashBucketEntry"})," (these records are identified as ",(0,i.jsx)(n.code,{children:"ReadCache"})," by a combination of ",(0,i.jsx)(n.code,{children:"TsavoriteKV.UseReadCache"})," being set ",(0,i.jsx)(n.em,{children:"and"})," the ReadCache bit in the ",(0,i.jsx)(n.code,{children:"RecordInfo"})," is set). All ",(0,i.jsx)(n.code,{children:"ReadCache"})," records come before any main log record. So (using r#### to indicate a ",(0,i.jsx)(n.code,{children:"ReadCache"})," record and m#### to indicate a main log record):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["When there are no ",(0,i.jsx)(n.code,{children:"ReadCache"})," entries in a hash chain, it looks like: ",(0,i.jsx)(n.code,{children:"HashTable"})," -> m4000 -> m3000 -> m..."]}),"\n",(0,i.jsxs)(n.li,{children:["When there are ",(0,i.jsx)(n.code,{children:"ReadCache"})," entries in a hash chain, it looks like: ",(0,i.jsx)(n.code,{children:"HashTable"})," -> r8000 -> r7000 -> m4000 -> m3000 -> m..."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["As a terminology note, the sub-chain of r#### records is referred to as the ",(0,i.jsx)(n.code,{children:"ReadCache"})," prefix chain of that hash chain."]}),"\n",(0,i.jsxs)(n.p,{children:["If the key is found in the readcache, then the ",(0,i.jsx)(n.code,{children:"RecordSource<TKey, TValue>.Log"})," is set to the readcache, and the logicalAddress is set to the readcache record's logicalAddress (which has the ReadCache bit). If the operation is a successful update (which will always be an RCU; readcache records are never themselves updated), the following steps happen:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:'The new version of the record is "spliced in" to the tag chain after the readcache prefix'}),"\n",(0,i.jsx)(n.li,{children:'The readcache "source" record is invalidated.'}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Using the above example and assuming an update of r8000, the resulting chain would be:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"HashTable"})," -> r8000 (invalid) -> r7000 -> mxxxx (new) -> m4000 -> m3000 -> m..."]}),"\n",(0,i.jsx)(n.li,{children:'In this example, note that the record address spaces are totally different between the main log and readcache; "xxxx" is used as the "new address" to symbolize this.'}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["This splicing operation requires that we deal with updates at the tail of the tag chain (in the ",(0,i.jsx)(n.code,{children:"HashEntryInfo"}),") as well as at the splice point. This cannot be done as a single atomic operation. To handle this, we detach the readcache prefix chain, insert the new record at the tail, and then reattach the detached records. See ",(0,i.jsx)(n.code,{children:"DetachAndReattachReadCacheChain"})," for specifics. We may fail the reattach, but this is acceptable (versus more complicated and expensive locking) because such failures should be rare and the readcache is just a performance optimization."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}}}]);