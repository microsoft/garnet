"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4334],{397:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-pfadd-few-keys-5052fa1e913d184cd21e6f3971a9cb13.png"},3727:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-getbit-setbit-batchsize-9a87d27dc06e7969f99f75cc85749ccf.png"},22700:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-get-batchsize-0fd6cd1821f5c0f9e3a4e69884d131d2.png"},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>o});var s=n(96540);const r={},a=s.createContext(r);function i(e){const t=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(a.Provider,{value:t},e.children)}},32860:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-get-threads-3693a83a89d53e3a8c0814308c4d7c96.png"},38323:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-pfadd-batchsize-23481d24c0c83e9727ddbd4363660274.png"},49504:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-bitop-batchsize-e1f2f56f212c1cefc3efdb376c19ffd0.png"},56067:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-getbit-setbit-threads-7a24f3d7e677dd2432d568a29203fe26.png"},59045:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"benchmarking/results-resp-bench","title":"Evaluating Garnet\'s Performance Benefits","description":"We have tested Garnet thoroughly in a variety of deployment modes:","source":"@site/docs/benchmarking/results-resp-bench.md","sourceDirName":"benchmarking","slug":"/benchmarking/results-resp-bench","permalink":"/garnet/docs/benchmarking/results-resp-bench","draft":false,"unlisted":false,"editUrl":"https://github.com/microsoft/garnet/tree/main/website/docs/benchmarking/results-resp-bench.md","tags":[],"version":"current","frontMatter":{"id":"results-resp-bench","sidebar_label":"Results (Resp.bench)","Title":"Performance Results (Resp.bench)"},"sidebar":"garnetDocSidebar","previous":{"title":"Overview","permalink":"/garnet/docs/benchmarking/overview"},"next":{"title":"Resp.benchmark","permalink":"/garnet/docs/benchmarking/resp-bench"}}');var r=n(74848),a=n(28453);const i={id:"results-resp-bench",sidebar_label:"Results (Resp.bench)",Title:"Performance Results (Resp.bench)"},o="Evaluating Garnet's Performance Benefits",l={},c=[{value:"Setup",id:"setup",level:2},{value:"Basic Commands Performance",id:"basic-commands-performance",level:2},{value:"Throughput GET",id:"throughput-get",level:4},{value:"Latency GET/SET",id:"latency-getset",level:4},{value:"Complex Data Structures Performance",id:"complex-data-structures-performance",level:2},{value:"Hyperloglog",id:"hyperloglog",level:4},{value:"Bitmap",id:"bitmap",level:4}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components},{Details:s}=t;return s||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"evaluating-garnets-performance-benefits",children:"Evaluating Garnet's Performance Benefits"})}),"\n",(0,r.jsx)(t.p,{children:"We have tested Garnet thoroughly in a variety of deployment modes:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Same local machine for client and server"}),"\n",(0,r.jsx)(t.li,{children:"Two local machines - one client and one server"}),"\n",(0,r.jsx)(t.li,{children:"Azure Windows VMs"}),"\n",(0,r.jsx)(t.li,{children:"Azure Linux VMs"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Below, we focus on a selected few key results."}),"\n",(0,r.jsx)(t.h2,{id:"setup",children:"Setup"}),"\n",(0,r.jsxs)(t.p,{children:["We provision two Azure Standard F72s v2 virtual machines (72 vcpus, 144 GiB memory each) running Linux (Ubuntu 20.04), with accelerated TCP enabled.\nThe benefit of this SKU is that we are guaranteed not to be co-located with another VM, which will optimize the performance.\nOne machine runs different cache-store servers, and the other is dedicated to issuing workloads.\nWe use our benchmarking tool, called ",(0,r.jsx)(t.a,{href:"resp-bench",children:"Resp.benchmark"}),", to generate all results.\nWe compare Garnet to the latest open-source versions of Redis (v7.2), KeyDB (v6.3.4), and Dragonfly (v6.2.11) at the time of writing.\nWe use a uniform random distribution of keys in these experiments (Garnet\u2019s shared memory design benefits even more with skewed workloads).\nAll data fits in memory in these experiments.\nThe baseline systems were tuned and optimized as much as possible based on available information.\nBelow, we summarize for each system the startup configuration used for our experiments."]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Garnet"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"      dotnet run -c Release --framework=net8.0 --project Garnet/main/GarnetServer -- \\\n            --bind $host \\\n            --port $port \\\n            --no-pubsub \\\n            --no-obj \\\n            --index 1g\n"})})]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Redis 7.2"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:'      ./redis-server \\\n            --bind $host \\\n            --port $port \\\n            --logfile "" \\\n            --save "" \\\n            --appendonly no \\\n            --protected-mode no \\\n            --io-threads 32\n'})})]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"KeyDB 6.3.4"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:'      ./keydb-server \\\n            --bind $host \\\n            --port $port \\\n            --logfile "" \\\n            --protected-mode no \\\n            --save "" \\\n            --appendonly no \\\n            --server-threads 16 \\\n            --server-thread-affinity true\n'})})]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Dragonfly 6.2.11"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:'      ./dragonfly \\\n              --alsologtostderr \\\n              --bind $host \\\n              --port $port \\\n              --df_snapshot_format false \\\n              --dbfilename "" \\\n              --max_client_iobuf_len 10485760\n'})})]}),"\n",(0,r.jsx)(t.h2,{id:"basic-commands-performance",children:"Basic Commands Performance"}),"\n",(0,r.jsx)(t.p,{children:"We measured throughput and latency for basic GET/SET operations by varying payload size, batch size, and number of client threads.\nFor our throughput experiments, we preload a small DB (1024 keys) and a large DB (256M keys) into Garnet before running the actual workload.\nIn contrast, our latency experiments were performed on an empty database and for a combined workload of GET/SET commands that operate on a small keyspace (1024 keys)."}),"\n",(0,r.jsx)(t.h4,{id:"throughput-get",children:"Throughput GET"}),"\n",(0,r.jsxs)(t.p,{children:["For the experiment depicted in Figure 1., we used large batches of GET operations (4096 requests per batch) and small payloads (8-byte keys and values) to minimize network overhead.\nAs we increase the number of client sesssions, we observe that ",(0,r.jsx)(t.strong,{children:"Garnet"})," exhibits better scalability than Redis or KeyDB.\nDragonfly exhibits similar scaling characteristics though only up to 16 threads. Note also, that DragonFly is a pure in-memory system.\nOverall, ",(0,r.jsx)(t.strong,{children:"Garnet"}),"'s throughput relative to the other systems is consistently higher even when the database size (i.e., the number of distinct keys pre-loaded) is larger (at 256 million keys) than the size of the processor cache."]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Varying number of client sessions or batchsize (GET)"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"    dotnet run -c Release --framework=net8.0 --project Garnet/benchmark/Resp.benchmark \\\n      --host $host \\\n      --port $port \\\n      --op GET \\\n      --keylength 8 \\\n      --valuelength $valuelength \\\n      --threads 1,2,4,8,16,32,64,128 \\\n      --batchsize $batchsize \\\n      --dbsize $dbsize\n"})})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-get-threads.png",src:n(32860).A+"",width:"1809",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 1: Throughput (log-scale), varying number of client sessions, for a database size of (a) 1024 keys, and (b) 256 million keys"})})})]}),"\n",(0,r.jsxs)(t.p,{children:["Even for small batch sizes ",(0,r.jsx)(t.strong,{children:"Garnet"})," outperforms the competing systems by attaining a consistently a higher throughput, as indicated by Figure 2.\nThis happens irrespective of the actual database size."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-get-batchsize.png.png",src:n(22700).A+"",width:"1809",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 2: Throughput (log-scale), varying batch sizes, for a database size of (a) 1024 keys, and (b) 256 million keys"})})})]}),"\n",(0,r.jsx)(t.h4,{id:"latency-getset",children:"Latency GET/SET"}),"\n",(0,r.jsxs)(t.p,{children:["We next measure client-side latency for various systems, by issuing a mixture of 80% GET and 20% SET requests, and compare it against ",(0,r.jsx)(t.strong,{children:"Garnet"}),".\nSince we care about latency, our DB size is kept small while we vary other parameters of the workload such as client threads, batch size, and payload size."]}),"\n",(0,r.jsx)(t.p,{children:"Figure 3, showcase that as increase the number of client sessions, Garnet's latency (measured in microseconds) and across various percentiles is consistently lower and more stable compared to other systems. Note this experiment does not utilize batching."}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Latency benchmark varying client sessions or batchsize (GET/SET)"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"    dotnet run -c Release --framework=net8.0 --project Garnet/benchmark/Resp.benchmark\n      --host $host \\\n      --port $port \\\n      --batchsize 1 \\\n      --threads $threads \\\n      --client GarnetClientSession \\\n      --runtime 35 \\\n      --op-workload GET,SET \\\n      --op-percent 80,20 \\\n      --online \\\n      --valuelength $valuelength \\\n      --keylength $keylength \\\n      --dbsize 1024 \\\n      --itp $batchsize\n"})})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"lat-get-set-threads.png",src:n(88720).A+"",width:"2255",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 3: Latency, varying number of client sessions, at (a) median, (b) 99th percentile, and (c) 99.9th percentile"})})})]}),"\n",(0,r.jsxs)(t.p,{children:["Garnet\u2019s latency is fine-tuned for adaptive client-side batching and efficiently handling multiple sessions querying the system.\nFor our next set of experiments, we increase the batch sizes from 1 to 64 and plot latency at different percentiles below with 128 active client connections.\nAs illustrated in Figure 4, ",(0,r.jsx)(t.strong,{children:"Garnet"})," maintains stability and achieves lower overall latency compared to other systems when the batch size is increased."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"lat-get-set-batchsize.png",src:n(69128).A+"",width:"2255",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 4: Latency, varying batch sizes, at (a) median, (b) 99th percentile, and (c) 99.9th percentile"})})})]}),"\n",(0,r.jsx)(t.h2,{id:"complex-data-structures-performance",children:"Complex Data Structures Performance"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Garnet"})," supports a vast number of different complex data structures such as Hyperloglog, Bitmap, Sorted Sets, Lists etc.\nBelow, we present performance metrics for a select few of them."]}),"\n",(0,r.jsx)(t.h4,{id:"hyperloglog",children:"Hyperloglog"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Garnet"})," supports its own built-in Hyperloglog (HLL) data structure.\nThis is implemented using C# and it supports operations such as update (PFADD), compute an estimate (PFCOUNT) and merge (PFMERGE) two or more distinct HLL structures.\nHLL data structures are often optimized in terms of their memory footprint.\nOur implementation is no different, utilizing a sparse representation when the number of nonzero counts is low and a dense representation beyond a given fixed threshold for which\nthe trade-off between memory savings and the additional work performed for decompression is no longer attractive.\nEnabling efficient updates to the HyperLogLog (HLL) structure is essential for concurrent systems, such as Garnet.\nFor this reason, our experiments forcus specifically on the performance of PFADD and are deliberately designed to stress test our system for the following scenarios:"]}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsx)(t.li,{children:"Large number of high contention updates (i.e. batchsize 4096, DB of 1024 keys) for increasing number of threads or increasing payload size\nAfter a few insertions, the constructed HyperLogLog (HLL) structures will transition to utilizing the dense representation."}),"\n",(0,r.jsx)(t.li,{children:"Large number of low contention updates (i.e. batchsize 4096, DB of 256M keys) for increasing number of threads or increasing payload size\nThis adjustment will increase the likelihood that the constructed HyperLogLog (HLL) structures utilize the sparse representation.\nConsequently, our measurements will consider the added overhead of working with compressed data or incrementally allocating more space for non-zero values"}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["In Figure 5, we present the results for first experimental scenario.\n",(0,r.jsx)(t.strong,{children:"Garnet"})," scales very well under high contention and consistently outperforms every other system in terms of raw throughput for increasing number of threads.\nSimilarly, for increasing payload size ",(0,r.jsx)(t.strong,{children:"Garnet"})," exhibits higher total throughput compared to other systems.\nAcross all tested systems, we noticed a noticeable decrease in throughput as the payload size increased.\nThis behavior is anticipated due to the inherent TCP network bottleneck."]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Varying number of client sessions or payload size while operating on few keys"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"    dotnet run -c Release --framework=net8.0 --project Garnet/benchmark/Resp.benchmark \\\n      --host $host \\\n      --port $port \\\n      --op PFADD \\\n      --keylength 8 \\\n      --valuelength $valuelength \\\n      --threads 1,2,4,8,16,32,64,128 \\\n      --batchsize 4096 \\\n      --dbsize 1024 \\\n      --skipload\n"})})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-pfadd-few-keys.png",src:n(397).A+"",width:"1990",height:"667"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 5: Throughput (log-scale), for (a) increasing number of client sessions, and (b) increasing payload size, for a database size of 1024 keys."})})})]}),"\n",(0,r.jsxs)(t.p,{children:["Figure 6 shows the results for the second experimental scenario as described above.\nEven while operating on the HLL sparse representation, ",(0,r.jsx)(t.strong,{children:"Garnet"})," performs better that any other system and achieves consistently higher throughput while scaling very well for increasing numbers of client sessions.\nSimilarly, for increasing payload size, ",(0,r.jsx)(t.strong,{children:"Garnet"})," outperforms the competition by scoring overall higher throughput.\nNotice in both cases the throughput is lower compared to the previous experiment due to the overhead of operating on compressed data."]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Varying number of client sessions or payload size while operating on many keys (PFADD)"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"    dotnet run -c Release --framework=net8.0 --project Garnet/benchmark/Resp.benchmark \\\n      --host $host \\\n      --port $port \\\n      --op PFADD \\\n      --keylength 8 \\\n      --valuelength $valuelength \\\n      --threads 1,2,4,8,16,32,64,128 \\\n      --batchsize 4096 \\\n      --dbsize 1048576 \\\n      --totalops 1048576 \\\n      --skipload\n"})})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-pfadd-few-keys.png",src:n(82246).A+"",width:"1793",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 6: Throughput (log-scale), for (a) increasing number of client sessions, and (b) increasing payload size, for a database size of 1M keys."})})})]}),"\n",(0,r.jsxs)(t.p,{children:["In Figure 7, we perform the same type of experiment as previously stated fixing the number of client sessions to 64, and the payload to 128 bytes while increasing the batchsize.\nNote that even for batch size of 4, ",(0,r.jsx)(t.strong,{children:"Garnet's"})," throughput gains are noticeably higher than any other system that we tested.\nThis demonstrates that even for small batch size we still outperform the competing systems."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-pfadd-batchsize.png",src:n(38323).A+"",width:"1805",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 7: Throughput (log-scale), for increasing batchsize by 64 client sessions on a DB with (a) 1024 keys, (b) 1M keys."})})})]}),"\n",(0,r.jsx)(t.h4,{id:"bitmap",children:"Bitmap"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Garnet"})," supports a set of bit-oriented operators on string data types.\nThese operators can be processed in constant time (i.e. GETBIT, SETBIT) or linear time (i.e. BITCOUNT, BITPOS, BITOP).\nTo speedup processing, for the linear time operators, we used hardware and SIMD instructions.\nBelow we present the benchmark results for a subset of these operators, covering both complexity categories.\nSimilarly to before we use a small DB size (1024 keys) to evaluate the performance of each system under high contention while avoiding\nhaving all the data resident in CPU cache by increasing the paylaod size (1MB)."]}),"\n",(0,r.jsxs)(t.p,{children:["In Figure 8, we present the performance metrics for GETBIT and SETBIT commands.\nIn both cases,  ",(0,r.jsx)(t.strong,{children:"Garnet"})," consistently maintains higher throughput and better scalability as the number of client sessions increase."]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Varying number of client sessions (GETBIT/SETBIT/BITOP_NOT/BITOP_AND)"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"    dotnet run -c Release --framework=net8.0 --project Garnet/benchmark/Resp.benchmark \\\n      --host $host \\\n      --port $port \\\n      --op GETBIT \\\n      --keylength 8 \\\n      --valuelength 1048576 \\\n      --threads 1,2,4,8,16,32,64,128 \\\n      --batchsize 4096 \\\n      --dbsize 1024        \n"})})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-getbit-setbit-threads.png",src:n(56067).A+"",width:"1809",height:"601"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 8: Throughput (log-scale), varying number of client sessions, for a database size of 1024 keys and 1MB payload."})})})]}),"\n",(0,r.jsxs)(t.p,{children:["In Figure 9, we evaluate the performance of BITOP NOT and BITOP AND (with two source keys) for increasing number of threads and a payload size of 1MB.\n",(0,r.jsx)(t.strong,{children:"Garnet"})," maintains overall higher throughput as the number of client session increases, compared to every other system we tested.\nIt also performs very well under high contention, given that our DB size is relatively small (i.e., only 1024 keys)."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-bitop-threads.png",src:n(94760).A+"",width:"1809",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 9: Throughput (log-scale), varying number of client sessions, for a database size of 1024 keys and 1MB payload."})})})]}),"\n",(0,r.jsxs)(t.p,{children:["As show in Figures 10 and 11, even for small batch sizes, ",(0,r.jsx)(t.strong,{children:"Garnet"})," attains a higher throughput that any other system we tested on the associated bitmap\noperations.\nIn fact, we observe significantly higher throughput with ",(0,r.jsx)(t.strong,{children:"Garnet"})," even at a small batchsize of 4."]}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Varying batch size (GETBIT/SETBIT/BITOP_NOT/BITOP_AND)"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"    dotnet run -c Release --framework=net8.0 --project Garnet/benchmark/Resp.benchmark \\\n      --host $host \\\n      --port $port \\\n      --op GETBIT \\\n      --keylength 8 \\\n      --valuelength 1048576 \\\n      --threads 64 \\\n      --batchsize $batchsize \\\n      --dbsize 1024        \n"})})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-bitop-batchsize.png",src:n(3727).A+"",width:"1793",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 10: Throughput (log-scale), for increasing batchsize by 64 client sessions on a DB with 1024 keys and 1MB payload."})})})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.th,{style:{textAlign:"center"},children:(0,r.jsx)(t.img,{alt:"tpt-bitop-batchsize.png",src:n(49504).A+"",width:"1803",height:"602"})})})}),(0,r.jsx)(t.tbody,{children:(0,r.jsx)(t.tr,{children:(0,r.jsx)(t.td,{style:{textAlign:"center"},children:"Figure 11: Throughput (log-scale), for increasing batchsize by 64 client sessions on a DB with 1024 keys and 1MB payload."})})})]})]})}function d(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},69128:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/lat-get-set-batchsize-e44fb214d8cf4861c3f950af04382987.png"},82246:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-pfadd-many-keys-8e6963a116394d6bddc7c9e39dd803a5.png"},88720:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/lat-get-set-threads-b08d9066b612f0c5198010d36d86a025.png"},94760:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/tpt-bitop-threads-c7d71faae4f7da0cee761d0fe4565863.png"}}]);